{"cells":[{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["# Program to scrape website and save quotes from the website\n","import requests\n","from bs4 import BeautifulSoup\n","import csv\n","\n","URL = \"http://www.values.com/inspirational-quotes\"\n","r = requests.get(URL)\n","\n","soup = BeautifulSoup(r.content, 'html5lib')\n","\n","quotes=[] # list to store quotes\n","\n","table = soup.find('div', attrs = {'id':'all_quotes'})\n","\n","for row in table.findAll('div',\n","\t\t\t\t\t\tattrs = {'class':'col-6 col-lg-3 text-center margin-30px-bottom sm-margin-30px-top'}):\n","\tquote = {}\n","\tquote['theme'] = row.h5.text\n","\tquote['url'] = row.a['href']\n","\tquote['img'] = row.img['src']\n","\tquote['lines'] = row.img['alt'].split(\" #\")[0]\n","\tquote['author'] = row.img['alt'].split(\" #\")[1]\n","\tquotes.append(quote)\n","\n","filename = 'inspirational_quotes.csv'\n","with open(filename, 'w', newline='') as f:\n","\tw = csv.DictWriter(f,['theme','url','img','lines','author'])\n","\tw.writeheader()\n","\tfor quote in quotes:\n","\t\tw.writerow(quote)"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"ename":"AttributeError","evalue":"'NoneType' object has no attribute 'findAll'","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)","Cell \u001b[1;32mIn[1], line 37\u001b[0m\n\u001b[0;32m     33\u001b[0m list3\u001b[39m=\u001b[39m[]\n\u001b[0;32m     35\u001b[0m \u001b[39m#make a simple loop\u001b[39;00m\n\u001b[1;32m---> 37\u001b[0m \u001b[39mfor\u001b[39;00m row \u001b[39min\u001b[39;00m table\u001b[39m.\u001b[39;49mfindAll(\u001b[39m'\u001b[39m\u001b[39mtr\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m     38\u001b[0m     table_data \u001b[39m=\u001b[39m row\u001b[39m.\u001b[39mfindAll(\u001b[39m'\u001b[39m\u001b[39mtd\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     39\u001b[0m     \u001b[39m# store second column data\u001b[39;00m\n","\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'findAll'"]}],"source":["# import libraries\n","\n","import requests\n","from bs4 import BeautifulSoup\n","import pandas as pd\n","\n","# base url which you want to scrap\n","\n","base_url = ('https://en.wikipedia.org/wiki/List_of_state_and_union_territory_capitals_in_India')\n","\n","# Make a get request to server\n","\n","r = requests.get(base_url)\n","\n","# initialize the soup object\n","\n","soup = BeautifulSoup(r.text, 'html.parser')\n","\n","# define the HTML table and class\n","\n","table=soup.find('table', class_\n","\n","='wikitable sortable plainrowheaders')\n","\n","# declare empty lists\n","\n","list1=[]\n","\n","list2=[]\n","\n","list3=[]\n","\n","# make a simple loop\n","\n","for row in table.findAll('tr'):\n","    table_data = row.findAll('td')\n","    # store second column data\n","    table_head = row.findAll('th')\n","# only extract table body not heading\n","if len(table_data)==6:\n","    list1.append\n","    (table_data[0].find(text=True))\n","    list2.append\n","    (table_head[0].find(text=True))\n","    list3.append\n","    (table_data[1].find(text=True))\n","    print('\\n')\n","\n","df=pd.DataFrame(list1,columns=['Number'])\n","\n","df['States/UT']=list2\n","\n","df['Capital']=list3\n","\n","# copy data frame in to CSV file\n","\n","# csv file has been created in current working directory\n","\n","df.to_csv('wiki.csv')\n","\n","# read scraped data from CSV file\n","\n","read=pd.read_csv\n","\n","('/home/soft27/.config/spyder-py3/wiki.csv')\n","\n","print('Reading data from csv file')\n","\n","print(read)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.4"},"orig_nbformat":4},"nbformat":4,"nbformat_minor":2}
